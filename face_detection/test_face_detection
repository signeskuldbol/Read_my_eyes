import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
from tqdm import tqdm

# -------------------------
# Settings (edit these)
# -------------------------
MODEL_PATH = "horse_blink/face_detection/yolov8l_horse_face_detection.pt"          # path to YOLO model
VIDEO_PATH = "horse_blink/face_detection/S1_Video.mp4"              # path to input video
OUTPUT_PATH = "horse_blink/face_detection/output_cropped.mp4"    # path to save cropped video
DEVICE = "cuda"                        # "cuda", "cuda:0", or "cpu"
CONF_THRES = 0.25                     # YOLO confidence threshold
PAD = 0                              # extra pixels around crop
KEEP_LAST_CENTER = True             # if a frame has no detection, use last known center
FALLBACK_TO_IMAGE_CENTER = True     # if no last center exists, use image center
CLASS_NAME = None                   # e.g. "horse" or None to use all classes
# Optional: force a square window using the max(width, height)
FORCE_SQUARE = False
# -------------------------


# Load model
model = YOLO(MODEL_PATH)

# Resolve class id if CLASS_NAME is set
class_id_filter = None
if CLASS_NAME is not None:
    names = model.model.names if hasattr(model, "model") else model.names
    if isinstance(names, dict):
        inv = {v: k for k, v in names.items()}
    else:
        inv = {n: i for i, n in enumerate(names)}
    if CLASS_NAME not in inv:
        raise SystemExit(f"Class '{CLASS_NAME}' not found. Available: {list(inv.keys())}")
    class_id_filter = inv[CLASS_NAME]

# Open video
cap = cv2.VideoCapture(str(VIDEO_PATH))
if not cap.isOpened():
    raise RuntimeError(f"Could not open video {VIDEO_PATH}")
W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0

# Prepare output video writer
fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(str(OUTPUT_PATH), fourcc, FPS, (W, H))
if not out.isOpened():
    raise RuntimeError(f"Could not open output video for write: {OUTPUT_PATH}")

